n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analval=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
a=5;
b=5;
n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analvals=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
sdd
a=50;
b=10;
n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analvals=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
#(a,b)=(5,5)
#> sdd
#[1] 0.1226287745 0.0306917376 0.0048920820 0.0038561923 0.0009259101
sdd
a=10;
b=50;
n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analvals=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
#(a,b)=(5,5)
#> sdd
#[1] 0.1226287745 0.0306917376 0.0048920820 0.0038561923 0.0009259101
#(a,b)=(50,10)
#> sdd
#[1] 0.021913624 0.053803132 0.009810062 0.001887827 0.001711349
#(a,b)=(10,50)
sdd
q()
library(LearnBayes)
data("studentdata")
barplot(table(studentdata$Drink), xlab="Drink", ylab="No: of people opting for the drink")
studentdata[1,]
barplot(table(studentdata$Drink,studentdata$Gender), xlab="Drink", ylab="No: of people opting for the drink")
barplot(table(studentdata$Gender,studentdata$Drink), xlab="Drink", ylab="No: of people opting for the drink")
counts=table(studentdata$Gender,studentdata$Drink)
barplot(counts, xlab="Drink", ylab="No: of people opting for the drink",legend=rownames(counts))
a=5;
b=5;
n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analvals=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
analvals
estvals
#(a,b)=(5,5)
#> sdd
#[1] 0.1226287745 0.0306917376 0.0048920820 0.0038561923 0.0009259101
#(a,b)=(50,10)
#> sdd
#[1] 0.021913624 0.053803132 0.009810062 0.001887827 0.001711349
#(a,b)=(10,50)
#> sdd
#[1] 0.0411411802 0.0203257542 0.0015220300 0.0014585405 0.0002956598
a=50;
b=10;
n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analvals=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
analvals
estvals
a=10;
b=50;
n=20;
ybar=5;
quantiles=seq(.1,.9,by=.1);
analvals=qgamma(quantiles,a+n*ybar,b+n);
#Sampling from Gamma
sdd=rep(0,5);
for (i in 1:5){
N=10^i;
gsamples=rgamma(N,a+n*ybar,b+n);
estvals=quantile(gsamples,quantiles);
sdd[i]=sd(estvals-analvals);
}
analvals
estvals
q()
library("glmnet")
data=read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data",sep=",");
data=subset(data, select = -2 )
nrows=dim(data)[1];
ncols=dim(data)[2];
colMeans(data[,1:33])
scaleddata=scale(data[,1:33])
target=data[,34]
colMeans(scaleddata)
apply(scaleddata,2,sd)
smp_size=floor(0.7 * nrows)
set.seed(123)
train_ind = sample(seq_len(nrows), size = smp_size)
trainx=scaleddata[train_ind, ]
testx= scaleddata[-train_ind, ]
trainy=target[train_ind]
testy= target[-train_ind]
length(trainy)
dim(trainx)
glmmod<-glmnet(trainx,y=trainy,alpha=0,family='binomial')
plot(glmmod,xvar="lambda")
cv.glmmod= cv.glmnet(trainx,y=trainy,alpha=0,family='binomial',type.measure = "class")
plot(cv.glmmod)
coef(glmmod,s = best_lambda)
best_lambda = cv.glmmod$lambda.min
best_lambda = cv.glmmod$lambda.min
coef(glmmod,s = best_lambda)
train=read.table("data.train",sep=",",header=TRUE)
head(train)
test=read.table("data.test",sep=",",header=TRUE)
head(test)
library(rpart)
fit <- rpart(mpg~cylinders + displacement + horsepower + weight+acceleration,
method="anova", data=train, control=rpart.control(cp=0.0001), xval=5)
printcp(fit)
train=read.table("data.train",sep=",",header=TRUE)
train=read.table("C:\Users\Divya\Documents\Coursework\Data Mining\hw\hw4\data.train",sep=",",header=TRUE)
train=read.table("C:\\Users\\Divya\\Documents\\Coursework\\Data Mining\\hw\hw4\\data.train",sep=",",header=TRUE)
train=read.table("C:\\Users\\Divya\\Documents\\Coursework\\Data Mining\\hw\\hw4\\data.train",sep=",",header=TRUE)
head(train)
test=read.table("C:\\Users\\Divya\\Documents\\Coursework\\Data Mining\\hw\\hw4\\data.test",sep=",",header=TRUE)
head(test)
library(rpart)
fit <- rpart(mpg~cylinders + displacement + horsepower + weight+acceleration,
method="anova", data=train, control=rpart.control(cp=0.0001), xval=5)
printcp(fit)
best_cp <- fit$cptable[which.min(fit$cptable[,"xerror"]),"CP"]
best_cp
prunedtree = prune(fit, best_cp)
printcp(prunedtree)
plot(prunedtree, uniform=TRUE,main="Pruned Regression Tree for MPG ")
text(prunedtree, use.n=TRUE, all=TRUE, cex=.8)
library("rpart.plot")
prp(prunedtree, type=1, extra=1)
trainerr=(predict(prunedtree, newdata=train[,-1])-train[,1])
MSEtrain=(trainerr%*%trainerr)/length(trainerr)
MSEtrain
testerr=(predict(prunedtree, newdata=test[,-1])-test[,1])
MSEtest=(testerr%*%testerr)/length(testerr)
MSEtest
plot(predict(prunedtree, newdata=test[,-1]), test[,1], xlab="Predicted values",ylab="Target values", main="Pruned Regression tree" )
fitp<- rpart(mpg~cylinders + displacement + horsepower + weight+acceleration, method="poisson", data=train, control=rpart.control(cp=0.0001), xval=5)
printcp(fitp)
best_cp <- fitp$cptable[which.min(fitp$cptable[,"xerror"]),"CP"]
best_cp
prunedtreep = prune(fitp, best_cp)
printcp(prunedtreep)
trainerr=(predict(prunedtreep, newdata=train[,-1])-train[,1])
MSEtrain=(trainerr%*%trainerr)/length(trainerr)
MSEtrain
prunedtreep = prune(fitp, 0.00879895)
printcp(prunedtreep)
trainerr=(predict(prunedtreep, newdata=train[,-1])-train[,1])
MSEtrain=(trainerr%*%trainerr)/length(trainerr)
MSEtrain
testerr=(predict(prunedtreep, newdata=test[,-1])-test[,1])
MSEtest=(testerr%*%testerr)/length(testerr)
MSEtest
data(iris)
head(iris)
iris[,1:4]
numsetosa=length(which(iris$Species=="setosa"))
numversicolor=length(which(iris$Species=="versicolor"))
numvirginica=length(which(iris$Species=="virginica"))
tapply(iris$Sepal.Length, factor(iris$Species),mean)
#setosa versicolor  virginica
#5.006      5.936      6.588
tapply(iris$Sepal.Width, factor(iris$Species),mean)
#setosa versicolor  virginica
#3.428      2.770      2.974
tapply(iris$Petal.Length, factor(iris$Species),mean)
#setosa versicolor  virginica
#1.462      4.260      5.552
tapply(iris$Petal.Width, factor(iris$Species),mean)
#setosa versicolor  virginica
#0.246      1.326      2.026
colMeans(iris[,1:4])
#Sepal.Length  Sepal.Width Petal.Length  Petal.Width
#5.843333     3.057333     3.758000     1.199333
init=matrix(c(5.006,5.936,6.588,3.428,2.770,2.974,1.462,4.260,5.552,0.246,1.326,2.026),3,4)
tmean=matrix(c(5.843333,3.057333,3.758000,1.199333),1,4)
start=rbind(init,tmean)
start
fit=kmeans(iris[,1:4],start)
table(iris$Species, fit$cluster)
qnorm(.99)
(.7/2.326)^2
qnorm(.95)
dnorm(0)
dnorm(0,.001)
dnorm(1.96,.001)
help(normal)
??normal
??dnorm
(1.645/.7)^2
load("~/Coursework/Data Mining/hw/hw5/imbalanced.RData")
set.seed(10)
head(trdata)
head('trdata')
trdata
load("~/Coursework/Data Mining/hw/hw5/imbalanced.RData")
trdata
tedata
trdat
head('trdat')
head(trdat)
fit=glm( income~., data=trdat,family=binomial(link=probit))
income
summary(fit)
ncol(trdat)
head(trdat[,-15])
pred <- prediction( predict(fit,newx = tedat[,-15], type = "response",), tedat[,15])
library(ROCR)
pred <- prediction( predict(fit,newx = tedat[,-15], type = "response",), tedat[,15])
pred <- prediction( predict(fit,newx = tedat[,-15], type = "response"), tedat[,15])
predict(fit,newx = tedat[,-15])
predict(fit,newx = tedat[,-15],type='response')
pred <- prediction( predict(fit,newx = tedat[,-15], type='response'), tedat[,15])
nrow(predict(fit,newx = tedat[,-15], type='response'))
nrow(tedat[,15])
View(tedat)
pred <- prediction( as.matrix(predict(fit,newx = tedat[,-15], type='response')),as.matrix(tedat[,15]))
pred <- prediction( as.matrix(predict(fit,newx = tedat[,-15], type='response')),as.factor(tedat[,15]))
tedat[,15]
as.factor(tedat[,15])
ytest=tedat[,15]=='large'
ytest[ytest==TRUE]=1
ytest[ytest==FALSE]=0
head(ytest)
ytest
pred <- prediction( predict(fit,newx = tedat[,-15], type='response'), ytest)
pred <- prediction( predict(fit,newx = tedat[,-15], type='class'), ytest)
pred <- prediction( predict(fit,newx = tedat[,-15]), ytest)
pred <- prediction( as.matrix(predict(fit,newx = tedat[,-15])), as.matrix(ytest))
nrow(ytest)
nrow(as.matrix(ytest))
nrow(as.matrix(predict(fit,newx = tedat[,-15])))
pred <- prediction( as.matrix(predict(fit,newdata = tedat[,-15])), as.matrix(ytest))
pred <- prediction( as.matrix(predict(fit,newdata = tedat[,-15], type='response')), as.matrix(ytest))
pred <- prediction( predict(fit,newdata = tedat[,-15], type='response'), ytest)
attributes(performance(pred, 'auc'))$y.values[[1]]
library('caret')
tr_up=upSample(trdat)
tr_up=upSample(trdat[,-15],trdat[,15])
p=sum(trdat[,15]=='large')/nrow(trdat)
p
p_up=sum(tr_up[,15]=='large')/nrow(tr_up)
p_down=sum(tr_down[,15]=='large')/nrow(tr_down)
tr_down=downSample(trdat[,-15],trdat[,15])
p_up=sum(tr_up[,15]=='large')/nrow(tr_up)
p_down=sum(tr_down[,15]=='large')/nrow(tr_down)
p_up
p_down
fit1=glm( income~., data=tr_up,family=binomial(link=probit))
head(tr_up)
fit1=glm( Class~., data=tr_up,family=binomial(link=probit))
tr_up$Class
pred <- prediction( predict(fit1,newdata = tedat[,-15], type='response'), ytest)
attributes(performance(pred, 'auc'))$y.values[[1]]
fit2=glm( Class~., data=tr_down,family=binomial(link=probit))
pred <- prediction( predict(fit2,newdata = tedat[,-15], type='response'), ytest)
pred <- prediction( predict(fit2,newdata = tedat[,-15], type='response',na.action = na.pass), ytest)
pred <- prediction( predict(fit2,newdata = tedat[,-15], type='response',na.action = na.exclude), ytest)
tr_down=downSample(trdat[,-15],trdat[,15])
fit2=glm( Class~., data=tr_down,family=binomial(link=probit))
pred <- prediction( predict(fit2,newdata = tedat[,-15], type='response',na.action = na.exclude), ytest)
attributes(performance(pred, 'auc'))$y.values[[1]]
pred <- prediction( predict(fit,newdata = tedat[,-15], type='response'), ytest)
attributes(performance(pred, 'auc'))$y.values[[1]]
trdat[,15]=as.numeric(trdat[,15])
library("kernlab")
install.packages('kernlab')
library("kernlab")
svp <- ksvm(trdat[,15]~., data= trdat,kernel='vanilladot',type="C-svc", class.weights = NULL)
svp.predict <-predict(svp,tedat,type="r")
fit3 =ksvm(income~., data= trdat,kernel='vanilladot',type="C-svc", class.weights = NULL)
pred <- prediction( predict(fit3,tedat[,-15],type="r"), tedat[,15])
attributes(performance(pred, 'auc'))$y.values[[1]]
fit4 =ksvm(income~., data= trdat,kernel='vanilladot',type="C-svc", class.weights = c("1"=1/3,"2"=2/3))
pred <- prediction( predict(fit4,tedat[,-15],type="r"), tedat[,15])
attributes(performance(pred, 'auc'))$y.values[[1]]
pred <- prediction( predict(fit4,newdata=tedat[,-15],type="r"), tedat[,15])
attributes(performance(pred, 'auc'))$y.values[[1]]
fit3 =ksvm(income~., data= trdat,kernel='vanilladot',type="C-svc", class.weights = NULL)
library(ISLR)
install.packages('ISLR')
library(ISLR)
train = 1:1000
names(Caravan)
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train, ]
Caravan.test = Caravan[-train, ]
library(gbm)
install.packages('gbm')
library(gbm)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(boost.caravan)
library(ISLR)
attach(Carseats)
train=sample(1:nrow(Carseats),nrow(Carseats)*.75)
Carseats.test=Carseats[-train,]
install.packages('tree')
library(tree)
ntrain=nrow(Carseats)*.75
train=sample(1:nrow(Carseats),ntrain)
Carseats.test=Carseats[-train,]
Carseats.train=Carseats[train,]
tree.carseats=tree(Sales~.,Carseats.train)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats,Carseats.test,type="class")
tree.pred=predict(tree.carseats,Carseats.test)
RMSE=sqrt(mean((tree.pred-Carseats.test$Sales)^2))
RMSE
cv.carseats=cv.tree(tree.carseats)
cv.carseats
min(cv.carseats$dev)
which.min(cv.carseats$dev)
cv.carseats$size[which.min(cv.carseats$dev)]
prune.carseats=prune.tree(tree.carseats,best=best)
prune.carseats=prune.tree(tree.carseats,best=3)
tree.pred=predict(prune.carseats,Carseats.test)
RMSE_prune=sqrt(mean((tree.pred-Carseats.test$Sales)^2))
RMSE_prune
install.packages('randomForest')
library('randomForest')
bag.carseats=randomForest(Sales~.,data=Carseats.train,mtry=10,importance=TRUE)
bagpred=predict(bag.carseats,Carseats.test)
RMSE=sqrt(mean((bagpred-Carseats.test$Sales)^2))
RMSE
importance(bag.carseats)
which.max(importance(bag.carseats)$IncNodePurity)
nrow(importance(bag.carseats))
ncol(importance(bag.carseats))
which.max(importance(bag.carseats)[,2])
for (i in 3:15){}
bag.carseats=randomForest(Sales~.,data=Carseats.train,mtry=i,importance=TRUE)
bagpred=predict(bag.carseats,Carseats.test)
RMSE=sqrt(mean((bagpred-Carseats.test$Sales)^2))
print(RMSE)
print(which.max(importance(bag.carseats)[,2]))
}
for (i in 3:15){
bag.carseats=randomForest(Sales~.,data=Carseats.train,mtry=i,importance=TRUE)
bagpred=predict(bag.carseats,Carseats.test)
RMSE=sqrt(mean((bagpred-Carseats.test$Sales)^2))
print(RMSE)
print(which.max(importance(bag.carseats)[,2]))
}
for (i in 3:15){
bag.carseats=randomForest(Sales~.,data=Carseats.train,mtry=i,importance=TRUE)
bagpred=predict(bag.carseats,Carseats.test)
RMSE=sqrt(mean((bagpred-Carseats.test$Sales)^2))
print(i)
print(RMSE)
print(which.max(importance(bag.carseats)[,2]))
}
table(Caravan.test$Purchase, boost.pred)
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train, ]
Caravan.test = Caravan[-train, ]
library(gbm)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(boost.caravan)
boost.prob = predict(boost.caravan, Caravan.test, n.trees = 1000, type = "response")
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.pred)
boost.prob = predict(boost.caravan, Caravan.test, n.trees = 1000, type = "response")
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.pred)
set.seed(300)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(boost.caravan)
head(trdat)
library(ISLR)
train = 1:1000
Caravan$Purchase = ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train = Caravan[train, ]
Caravan.test = Caravan[-train, ]
library(gbm)
set.seed(300)
boost.caravan = gbm(Purchase ~ ., data = Caravan.train, n.trees = 1000, shrinkage = 0.01, distribution = "bernoulli")
summary(boost.caravan)
boost.prob = predict(boost.caravan, Caravan.test, n.trees = 1000, type = "response")
boost.pred = ifelse(boost.prob > 0.2, 1, 0)
table(Caravan.test$Purchase, boost.pred)
setwd("~/Coursework/Statistical Modelling 1/HW/hw6")
data=read.table('nickeldata.dat')
head(data)
data=read.table('nickeldata.txt')
head(data)
data$V1
fit=glm(formula = V6 ~ V1+V2+V3+V4+offset(log(V10)), family = poisson,data = data)
summary(fit)
fit=glm(formula = V6 ~ V3+V4+V3*V3+V4*V4+V3*V4+offset(log(V10)), family = poisson,data = data)
summary(fit)
fit=glm(formula = V6 ~ V3+V4+Expsq+V3*V4+offset(log(V10)), family = poisson,data = data)
data$Expsq=data$V3*data$V3
fit=glm(formula = V6 ~ V3+V4+Expsq+V3*V4+offset(log(V10)), family = poisson,data = data)
summary(fit)
fit=glm(formula = V6 ~ V3+V4+offset(log(V10)), family = poisson,data = data)
summary(fit)
plot(fit$fitted,data$V6)
plot(fitted(fit),rstandard(fit),ylab=standardized deviance residuals)
plot(fitted(fit),rstandard(fit),ylab='standardized deviance residuals')
library('MASS')
fit.nb=glm.nb(V6 ~ V3+V4+offset(log(V10)), data)
summary(fit.nb)
plot(fitted(fit.nb),rstandard(fit.nb),ylab='standardized deviance residuals')
abline(h=0)
setwd("~/Coursework/Statistical Modelling 1/Project")
data=read.table('wtloss.txt', header=T)
head(data)
table(data$treatment)
attach(data)
hist(wtch)
boxplot(wtch~data$treatment,ylab="12 month weight change",xlab="Treatment")
tapply(wtch,treatment,mean)
hist(log(wtch))
fit=lm(wtch~as.factor(treatment)+age+as.factor(race)+biomarker)
summary(fit)
agesq=age*age
biosq=biomarker*biomarker
fit=lm(wtch~as.factor(treatment)+age+agesq+as.factor(race)+biomarker+agesq+biosq)
summary(fit)
race.f = factor(race)
dummies = model.matrix(~race.f)
dummies
trt.f = factor(treatment)
trtdummies = model.matrix(~trt.f)
trtdummies
N=nrow(data)
N
dum1=dummies[,2]
dum2=dummies[,3]
dum3=dummies[,4]
trt1=trtdummies[,2]
trt2=trtdummies[,3]
library("R2WinBUGS")
bugs.data(list(wtch=wtch, age=age,biomarker,r1=dum1,r2=dum2,r3=dum3,trt1=trt1,trt2=trt2,  N=N),data.file='Wtch.txt')
bugs.data(list(wtch=wtch, age=age,biomarker=biomarker,r1=dum1,r2=dum2,r3=dum3,trt1=trt1,trt2=trt2,  N=N),data.file='WtchBugs.txt')
data=read.table('nickeldata.txt')
setwd("~/Coursework/Statistical Modelling 1/HW/hw6")
data=read.table('nickeldata.txt')
head(data)
library('MASS')
fit.nb=glm.nb(V6 ~ V3+V4+offset((V10)), data)
attach(data)
fit.nb=glm.nb(V6 ~ V3+V4+offset((V10)), data)
fit=glm(formula = V6 ~ V3+V4+offset(log(V10)), family = poisson,data = data)
fit=glm(formula = V6 ~ V3+V4+offset((V10)), family = poisson,data = data)
fit=glm(formula = V6 ~ V3+V4+offset(log(V9)), family = poisson,data = data)
summary(fit)
plot(fitted(fit),rstandard(fit),ylab='standardized deviance residuals for offset=py')
setwd("~/Coursework/Data Mining/Project/TrustWalker/TrustBasedRecommender/code")
